{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d83c5fc-7e0f-41e5-aae1-e74739b47c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 동영상과 mediapipe-hand를 연결하기\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 손을 찾는 기능 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "# 특징점 그리기 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 손 특징점 찾기 관련 설정\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 2,\n",
    "    min_detection_confidence = 0.5, # 손 검출 확률(자체 판단) 50% 이상인것들만 출력하기 \n",
    "    min_tracking_confidence = 0.5# 특징점 검출 확률(자체 판단) 50% 이상인것들만 출력하기\n",
    ")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지에서 원하는 대상(손) 찾기\n",
    "    result = hands.process(img)\n",
    "    # 손을 검출 했다면 표현하기(21개의 특징점을 찾음)\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        # 21개 특징점을 하나씩 그려주기\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "\n",
    "    \n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(33) == 49:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cb6626-a748-44da-9a0f-ea738353a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 동영상과 mediapipe-hand를 연결하기\n",
    "## 한손의 동작 인식하기\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "gesture = {\n",
    "    0:'fist', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',\n",
    "    6:'six', 7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
    "}\n",
    "\n",
    "# gesture_train를 머신러닝 모델에 학습\n",
    "import numpy as np\n",
    "file = np.genfromtxt('images/gesture_train.csv',delimiter = ',')\n",
    "angle = file[:, :-1].astype(np.float32) # 문제데이터\n",
    "label = file[:, -1].astype(np.float32) # 정답데이터\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(angle,label)\n",
    "\n",
    "# 손을 찾는 기능 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "# 특징점 그리기 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 손 특징점 찾기 관련 설정\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence = 0.5, # 손 검출 확률(자체 판단) 50% 이상인것들만 출력하기 \n",
    "    min_tracking_confidence = 0.5# 특징점 검출 확률(자체 판단) 50% 이상인것들만 출력하기\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지에서 원하는 대상(손) 찾기\n",
    "    result = hands.process(img)\n",
    "    # 손을 검출 했다면 표현하기(21개의 특징점을 찾음)\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        # 21개 특징점을 하나씩 그려주기\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(33) == 49:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab850d79-8ca2-4d33-8aec-587fc3f0c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "max_num_hands = 2\n",
    "gesture = {\n",
    "    0:'fist', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',\n",
    "    6:'six', 7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
    "}\n",
    "rsp_gesture = {0:'rock', 5:'paper', 9:'scissors'}\n",
    "\n",
    "# MediaPipe hands model 가져오기\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=max_num_hands,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 제스쳐 인식 모델 학습하기\n",
    "file = np.genfromtxt('images/gesture_train.csv', delimiter=',')\n",
    "angle = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(angle, label)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = hands.process(img)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        rsp_result = []\n",
    "\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 3))\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            # joint들로 관절값 구하기\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # Child joint\n",
    "            v = v2 - v1 # [20,3]\n",
    "            # Normalize v 유클리디안 길이\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # 관절값으로 관절 각도 구하기\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle) # radian각도를 degree각도로 변경하기\n",
    "\n",
    "            # 제스쳐 인식시키기\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            results = knn.predict(data)\n",
    "            idx = int(results)\n",
    "\n",
    "            # 제스쳐 인식되면 표시하기\n",
    "            if idx in rsp_gesture.keys():\n",
    "                org = (int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0]))\n",
    "                cv2.putText(img, text=rsp_gesture[idx].upper(), org=(org[0], org[1] + 20), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "                rsp_result.append({\n",
    "                    'rsp': rsp_gesture[idx],\n",
    "                    'org': org\n",
    "                })\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Who wins?\n",
    "            if len(rsp_result) == 2:\n",
    "                winner = None\n",
    "                text = ''\n",
    "\n",
    "                if rsp_result[0]['rsp']=='rock':\n",
    "                    if rsp_result[1]['rsp']=='rock'     : text = 'Tie'\n",
    "                    elif rsp_result[1]['rsp']=='paper'  : text = 'Paper wins'  ; winner = 1\n",
    "                    elif rsp_result[1]['rsp']=='scissors': text = 'Rock wins'   ; winner = 0\n",
    "                elif rsp_result[0]['rsp']=='paper':\n",
    "                    if rsp_result[1]['rsp']=='rock'     : text = 'Paper wins'  ; winner = 0\n",
    "                    elif rsp_result[1]['rsp']=='paper'  : text = 'Tie'\n",
    "                    elif rsp_result[1]['rsp']=='scissors': text = 'Scissors wins'; winner = 1\n",
    "                elif rsp_result[0]['rsp']=='scissors':\n",
    "                    if rsp_result[1]['rsp']=='rock'     : text = 'Rock wins'   ; winner = 1\n",
    "                    elif rsp_result[1]['rsp']=='paper'  : text = 'Scissors wins'; winner = 0\n",
    "                    elif rsp_result[1]['rsp']=='scissors': text = 'Tie'\n",
    "\n",
    "                if winner is not None:\n",
    "                    cv2.putText(img, text='Winner', org=(rsp_result[winner]['org'][0], rsp_result[winner]['org'][1] + 70), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 255, 0), thickness=3)\n",
    "                cv2.putText(img, text=text, org=(int(img.shape[1] / 3), 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 0, 255), thickness=3)\n",
    "\n",
    "    cv2.imshow('Game', img)\n",
    "    # if cv2.waitKey(1) == 49:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb61485-131f-42b3-8efc-edb74391eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "gesture = {\n",
    "    0:'fist', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',\n",
    "    6:'six', 7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
    "}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "file = np.genfromtxt('images/gesture_train.csv', delimiter=',')\n",
    "angle = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(angle, label)\n",
    "\n",
    "# 얼굴에서 특징점 찾기 관련 기능\n",
    "mp_face = mp.solutions.face_mesh\n",
    "# 특징점 연결 관련 기능\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 얼굴 찾기 기능\n",
    "face = mp_face.FaceMesh(\n",
    "    min_detection_confidence = 0.5, # 정확한 얼굴 찾기\n",
    "    min_tracking_confidence = 0.5 # 얼굴 위치 찾기\n",
    ")\n",
    "\n",
    "spiderman = cv2.imread('images/spiderman.jpg',cv2.IMREAD_COLOR)\n",
    "spiderman = cv2.resize(spiderman,(250,250))\n",
    "\n",
    "# 카메라에 보이는 얼굴 영역 크기만큼 조절\n",
    "mask2gray = cv2.cvtColor(spiderman, cv2.COLOR_RGB2GRAY)\n",
    "_, mask_b = cv2.threshold(mask2gray, 220, 255, cv2.THRESH_BINARY)\n",
    "mask_b_inv = cv2.bitwise_not(mask_b)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "\n",
    "    \n",
    "    hand_result = hands.process(frame)\n",
    "    try:\n",
    "        if hand_result.multi_hand_landmarks is not None:\n",
    "            for res in hand_result.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 3))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "                # joint들로 관절값 구하기\n",
    "                v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # Parent joint\n",
    "                v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # Child joint\n",
    "                v = v2 - v1 # [20,3]\n",
    "                # Normalize v 유클리디안 길이\n",
    "                v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                # 관절값으로 관절 각도 구하기\n",
    "                angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                    v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                    v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "                angle = np.degrees(angle) # radian각도를 degree각도로 변경하기\n",
    "\n",
    "                # 제스쳐 인식시키기\n",
    "                data = np.array([angle], dtype=np.float32)\n",
    "                results = knn.predict(data)\n",
    "                idx = int(results)\n",
    "                            # 제스쳐 인식되면 표시하기\n",
    "                if idx == 7 or idx == 8: # rock을 스파이더맨으로 인식\n",
    "                    cv2.putText(frame, text='SpiderMan', org=(int(res.landmark[0].x * frame.shape[1]), int(res.landmark[0].y * frame.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "                # Other gestures\n",
    "                #cv2.putText(frame, text=gesture[idx].upper(), org=(int(res.landmark[0].x * frame.shape[1]), int(res.landmark[0].y * frame.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "                    face_result = face.process(frame)\n",
    "                \n",
    "                    # 이미지에서 얼굴을 찾으면 실행\n",
    "                    if face_result.multi_face_landmarks is not None:\n",
    "                        # 478개의 점을 얼굴에 찍기\n",
    "                        # for res in face_result.multi_face_landmarks:\n",
    "                        #     # 점을찍고 선으로 연결하기\n",
    "                        #     mp_drawing.draw_landmarks(frame, res, mp_face.FACEMESH_TESSELATION)\n",
    "                        # 478개 점의 값을 저장\n",
    "                        # 4번점이 코의 위치\n",
    "                        nose = face_result.multi_face_landmarks[0].landmark[4]\n",
    "                        # 코의 위치 출력\n",
    "                        # cv2.circle(frame,\n",
    "                        #            (int(nose.x * frame.shape[1]), int(nose.y * frame.shape[0])),\n",
    "                        #            20, (0,0,255), cv2.FILLED\n",
    "                        #           )\n",
    "                        nose_x = int(nose.x * frame.shape[1])\n",
    "                        nose_y = int(nose.y * frame.shape[0])\n",
    "                        # 123, 132\n",
    "                        roi = frame[nose_y-125:nose_y+125, nose_x-125:nose_x+125]\n",
    "                        frame_bg = cv2.bitwise_and(roi,roi,mask = mask_b)\n",
    "                        frame_fg = cv2.bitwise_and(spiderman,spiderman,mask = mask_b_inv)\n",
    "                        bg_fg = cv2.add(frame_bg,frame_fg)\n",
    "                        frame[nose_y-125:nose_y+125, nose_x-125:nose_x+125] = bg_fg\n",
    "                mp_drawing.draw_landmarks(frame, res, mp_hands.HAND_CONNECTIONS)\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 49:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa691f-dd56-4f30-982f-5bab9e5a2ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8a83e-40aa-4126-a2cf-725659da2aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d4386-12c1-4c6b-b293-ee9d849a79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51827b-2a41-4535-8c71-d1abfe5a28ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fc57a-adc8-4e07-8d2c-553b28256912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b7297-acff-426d-8c89-8e119d959bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f71d4-6dcd-450a-9c52-a23f4721e973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b136d3b-793c-4017-bb1b-dcc73ada5999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430b459-797e-4e7f-9d3f-e4b6997d23b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e8942-c41c-4184-9b78-e139e9c88ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d885fd6-276a-4c19-b97d-492ff65ab039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c0845-be62-4294-8833-ef7bae6ef3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c3f2e-d7a3-4124-ab15-9a3e7f001dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b829ed7-b157-4a40-b075-9647f5eca02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ad39e-99a9-4e3c-b004-6899469a0171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23d61e-ebed-40e7-b45c-40bb6238091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be16ee6-0ca7-46e4-a7a9-ef1cac1427dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225aa5bb-af72-4c48-b929-62aed61c67e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cbaca-cb57-4346-8576-4270bd791d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d140aa-e64f-47d8-98ee-71fd74ea8c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41961823-39a4-4680-ae31-4b3e7c943142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f32727-5ae5-428a-83f3-854a2f77dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16448c6-ca03-4e91-bafb-feb73666c41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
